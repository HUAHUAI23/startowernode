# 架构探究

## 架构图

MongoDB分片集群与MySQL中的水平分表类似。

以下是一个较为完美的分片集群部署策略图：

![image-20211219193536317](https://images-1302522496.cos.ap-nanjing.myqcloud.com/img/image-20211219193536317.png)



## 集群组成

名词解释：

- mongos ：路由节点，提供集群单一入口，转发application的请求至所有分片节点上，上图中3个mongos是保证了高可用性，mongos之间不用做复制集
- config ：配置节点，存储分片的配置策略，如分片开始位置，分片结束位置等，是整个分片集群的配置信息存储位置，上图3个config是为了保证高可用性
- shard ：分片节点，以复制集为单位，对于分片节点来说，横向扩展最大可支持1024个，每个分片节点上的数据不允许重复，所有分片在一起才能完整的进行工作

分片集群由多个分片节点+配置节点+路由节点构成，特点如下：

1. 分片集群对application是透明的，没有任何特殊处理
2. 分片集群对于数据来说会有自动均衡策略
3. 如果要对分片集群进行扩容，可在线上直接进行扩容而无需下线
4. MongoDB当前提供3种分片策略



# 分片相关

## 分片策略

MongoDB目前提供3种分片策略，如下所示：

- 基于范围，范围查询性能良好，侧重于读的性能，但是可能造成数据分布不均匀
- 基于Hash，数据分布均匀，侧重于写的性能，但是范围查询效率低
- 基于zones / tag，适用于大范围的全球性业务

基于范围分片的图示：

<img src="https://images-1302522496.cos.ap-nanjing.myqcloud.com/img/sharding-range-based.bakedsvg.svg" alt="sharding-range-based.bakedsvg" style="zoom: 50%;" />

基于Hash分片的图示：

<img src="https://images-1302522496.cos.ap-nanjing.myqcloud.com/img/sharding-hash-based.bakedsvg.svg" alt="sharding-hash-based.bakedsvg" style="zoom:50%;" />

基于Zones的分片：

<img src="https://images-1302522496.cos.ap-nanjing.myqcloud.com/img/sharded-cluster-zones.bakedsvg.svg" alt="sharded-cluster-zones.bakedsvg" style="zoom: 33%;" />





## 分片计算

如何计算当前业务需要多少个分片？下面是计算法则：

- 使用存储数据总量 / 单个服务器可挂载的容量 如：8TB / 2TB = 4
- 使用工作集的大小 / 单个服务器的内容容量\*0.6（不可能全部占满） 如：400GB / (256G \* 0.6) = 3
- 使用最高并发总数 / 单个服务器平均并发量\*0.7（一个复制集群是有损耗的） 如：3000 / (9000 \* 0.7) = 6

最终的分片数量采取3个结果中的最大值: max(4, 3, 6) = 6

对于分片的数据来说，每个分片节点的数据量都不应该超过3TB

对于分片的索引来说，必须保证常用的索引字段能够存放至内存中（查看文档索引，结合物理内存大小做计算）



## 分片名词

一些分片中常见的概念性名词，概念由小到大：

- 片键 shard key ：文档中的一个字段，由于MongoDB的分片类似于水平分表，所以我们必须指定拆分的字段列
- 文档 doc ：包含shard key的一行数据（对应到关系型数据库中，一个文档就是一行记录）
- 块 Chunk ： 一个块包含多个文档，每个块的大小为64MB
- 分片 Shard ： 一个分片节点中包含多个块，没有大小限制，但应该尽量保证单个分片的数据量在3TB下
- 集群 Cluster ： 一个分片集群中包含多个分片节点，通常情况下一个分片集群也必须是一个复制集群（保证高可用）



在选择片键时，要遵循以下几点原则，为了方便描述我均采用关系型数据库的概念来举例：

1. 取值应该基数大：如果对一个表来说，水平拆分时如果按照gender字段进行拆分，那么即使拆分成多个表，单表的数据量级依旧很大，最好的选择是根据id进行拆分
2. 取值应该分布均匀：如果对一个学生表来进行水平拆分，片键选择是年龄，年龄的基数虽然可以达到1-100，但是要注意业务场景，学生表的主要数据年龄为12-16岁（中学），这依然会造成单表的数据量级大的问题，所以按照年龄来进行拆分并不合适
3. 片键应该利于分散写：集中读：如果片键选择不合理，对于写来说则可能造成写入的数据的Chunk块先到第一个分片节点中，发现位置不对再向第二个分片节点进行迁移的情况，造成性能损耗，多做了无用功。而对于读来说则可能会导致扫描所有分片节点的操作，不能准确定位，造成查询效率低的问题

用以下几种情况来举例MongoDB中片键的选择案例，这里与关系型数据库有较大的差异，建议不要做横向对比。

情况1，按照\_id进行范围分片：

- 从基数的角度来看，使用\_id进行分片，因为_\id不会重复，所以是合理的
- 从写的角度看，由于\_id总是递增的，新插入的数据总会到达最后的一个分片节点，是合理的
- 从读的角度看，用于MongoDB的\_id与MySQL的id不同，因此没有人会用\_id作为查询条件，这可能导致会扫描所有分片节点，读的性能极低，是不合理的

情况2，按照phone进行hash分片：

- 从基数的角度来看，phone永远不会重复，是合理的
- 从写的角度来看，使用hash分片，能够准确的将数据插入到对应的分片节点中，是合理的
- 从读的角度来看，使用phone作为查询条件虽然可以很快的拿出单个用户的数据，但是对于范围查询来讲效率会偏慢，这是不合理的

情况3，按照用户的id（不是\_id）和phone进行分片：

- 从基数的角度来看，phone与用户id不会重复，是合理的
- 从写的角度来看，和上面一样，是合理的
- 从读的角度来看，无论是使用用户id或者phone进行读取，都能较快的拿出数据，是合理的



# 搭建过程

具体的搭建过程这里不再演示了，不过我找到一篇不错的MongoDB的分片集搭建文章，另外在搭建前保证每个服务器hostname不同应当是必要的。

[点我跳转](https://www.langxw.com/2021/03/12/Mongodb%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/)
